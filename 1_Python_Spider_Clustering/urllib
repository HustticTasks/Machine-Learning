urllib2:
	方法 urlopen(url,data,timeout):
	#data和timeout都存在默认参数可以不用传入
		data是访问时传送的数据，timeout是超时时间
		e.g. response = urllib2.urlopen("http://www.baidu.com")
	方法 read():
		返回获取的网页内容
		e.g. print( response.read() )
		#如果不加read直接打印，会返回该对象的描述
构造Request
	e.g. request = urllib2.Request("http://www.baidu.com")
	     response = urllib2.urlopen(request)
	     print ( response.read() )
	通过构建一个request，服务器响应请求得到应答，这样显得逻辑上清晰明确
POST和GET数据传送
	数据传送分为POST和GET两种方式
		POST方式：
			e.g. 
			import urllib
			import urllib2
	 
			values = {"username":"1016903103@qq.com","password":"XXXX"}#定义字典（也可以先定义空白字典，然后依次传入字典的key和value
			data = urllib.urlencode(values) #用urllib的urlencode()方法对字典编码
			url = "https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn"
			request = urllib2.Request(url,data)
			response = urllib2.urlopen(request)
			print response.read()
		GET方式：
			直接把参数写到网址上，构建带参数的URL
			e.g.
			import urllib
			import urllib2
	 
			values = {"username":"1016903103@qq.com","password":"XXXX"}
			data = urllib.urlencode(values) 
			url = "https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn"
			request = urllib2.Request(url,data)
			response = urllib2.urlopen(request)
			print response.read()
			#此时print URL 的结果是：http://passport.csdn.net/account/login？username=1016903103%40qq.com&password=XXXX
			#？后是编码后的参数
设置Headers
	整个网页效果是执行了多次请求之后才出现的。在Request Headers中包含有请求的agent. agent就是请求的身份。如果没有写入请求身份，那么服务器不一定会响应，所以可以在headers中设置agent

	e.g.
	import urllib  
	import urllib2  
	
	url = 'http://www.server.com/login'
	user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'  
	values = {'username' : 'cqc',  'password' : 'XXXX' }  
	headers = { 'User-Agent' : user_agent }  
	data = urllib.urlencode(values)  
	request = urllib2.Request(url, data, headers) #设置了一个Headers，在构建request时传入，在请求时就加入了Headers传送，服务器若识别了是浏览器发来的请求，就会得到响应。
	response = urllib2.urlopen(request)  
	page = response.read() 
	
	另外对付反盗链，服务器会识别headers中的referer是不是它自己，如果不是，有的服务器不会响应，所以我们还可以在headers中加入referer，比如可以如下构建Headers：
	
	e.g. 
	headers = { 'User-Agent' : 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'  ,
	                    'Referer':'http://www.zhihu.com/articles' }  
	
	#盗链是指服务提供商自己不提供服务的内容，通过技术手段绕过其它有利益的最终用户界面（如广告），直接在自己的网站上向最终用户提供其它服务提供商的服务内容，骗取最终用户的浏览和点击率。受益者不提供资源或提供很少的资源，而真正的服务提供商却得不到任何的收益。
	#盗链是指服务提供商自己不提供服务的内容，通过技术手段绕过其它有利益的最终用户界面（如广告），直接在自己的网站上向最终用户提供其它服务提供商的服务内容，骗取最终用户的浏览和点击率。受益者不提供资源或提供很少的资源，而真正的服务提供商却得不到任何的收益。
*一些Headers属性
	#User-Agent : 有些服务器或 Proxy 会通过该值来判断是否是浏览器发出的请求
	#Content-Type : 在使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析。
	#application/xml ： 在 XML RPC，如 RESTful/SOAP 调用时使用
	#application/json ： 在 JSON RPC 调用时使用
	#application/x-www-form-urlencoded ： 浏览器提交 Web 表单时使用
	#在使用服务器提供的 RESTful 或 SOAP 服务时， Content-Type 设置错误会导致服务器拒绝服务
Proxy（代理）的设置
	urllib2 默认会使用环境变量 http_proxy 来设置 HTTP Proxy。假如一个网站它会检测某一段时间某个IP 的访问次数，如果访问次数过多，它会禁止你的访问。所以你可以设置一些代理服务器来帮助你做工作，每隔一段时间换一个代理.
	e.g.
	import urllib2
	
	enable_proxy = True
	proxy_handler = urllib2.ProxyHandler({"http" : 'http://some-proxy.com:8080'})
	null_proxy_handler = urllib2.ProxyHandler({})
	if enable_proxy:
   	 	opener = urllib2.build_opener(proxy_handler)
	else:
			opener = urllib2.build_opener(null_proxy_handler)
	urllib2.install_opener(opener)


Timeout设置
	可以设置等待多久超时。如果data已经传入则不必写明实参timeout，若未传入则timeout不可省略
	e.g.
	response = urllib2.urlopen('http://www.baidu.com',timeout = 10)
	response = urllib2.urlopen('http://www.baidu.com',data,10)
*使用 HTTP 的 PUT 和 DELETE 方法
	http协议有六种请求方法，get,head,put,delete,post,options，我们有时候需要用到PUT方式或者DELETE方式请求。
	PUT：这个方法比较少见。HTML表单也不支持这个。本质上来讲， PUT和POST极为相似，都是向服务器发送数据，但它们之间有一个重要区别，PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。
	DELETE：删除某一个资源。基本上这个也很少见，不过还是有一些地方比如amazon的S3云服务里面就用的这个方法来删除资源。
	如果要使用 HTTP PUT 和 DELETE ，只能使用比较低层的 httplib 库。虽然如此，我们还是能通过下面的方式，使 urllib2 能够发出 PUT 或DELETE 的请求，不过用的次数较少。
	e.g.
	import urllib2
	
	request = urllib2.Request(uri, data=data)
	request.get_method = lambda: 'PUT' # or 'DELETE'
	response = urllib2.urlopen(request)

*使用DebugLog
	可以通过下面的方法把 Debug Log 打开，这样收发包的内容就会在屏幕上打印出来，方便调试.
	e.g.
	import urllib2
	
	httpHandler = urllib2.HTTPHandler(debuglevel=1)
	httpsHandler = urllib2.HTTPSHandler(debuglevel=1)
	opener = urllib2.build_opener(httpHandler, httpsHandler)
	urllib2.install_opener(opener)
	response = urllib2.urlopen('http://www.baidu.com')

