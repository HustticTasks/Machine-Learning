# 爬虫学习

## 1.HTML分析

## 2.urllib爬取

导入urllib包（Python3.5.2）

## 3.保存网页

```python
import urllib.request
url = "http://www.cnblogs.com/wj204/p/6151070.html"
html = urllib.request.urlopen(url).read()
fh=open("F:/20_Python/3000_Data/2.html","wb")
fh.write(html)
fh.close()
```

## 4正则表达式

```python
pat = 'pic_url":"//(.*?)"'
re.compile(pat).findall(data)
#需要提取的内容是（.*?），位于pic_url":"//和"之中
```

### match对象



> 1.string: 匹配时使用的文本。
>
>  2.re: 匹配时使用的Pattern对象。
>  3.pos: 文本中正则表达式开始搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。
>  4.endpos: 文本中正则表达式结束搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。
>  5.lastindex: 最后一个被捕获的分组在文本中的索引。如果没有被捕获的分组，将为None。
>  6.lastgroup: 最后一个被捕获的分组的别名。如果这个分组没有别名或者没有被捕获的分组，将为None。
>
> 方法：
>  1.group([group1, …]):
>
> 获得一个或多个分组截获的字符串；指定多个参数时将以元组形式返回。group1可以使用编号也可以使用别名；编号0代表整个匹配的子串；不填写参数时，返回group(0)；没有截获字符串的组返回None；截获了多次的组返回最后一次截获的子串。
>  2.groups([default]):
>  以元组形式返回全部分组截获的字符串。相当于调用group(1,2,…last)。default表示没有截获字符串的组以这个值替代，默认为None。
>  3.groupdict([default]):
>  返回以有别名的组的别名为键、以该组截获的子串为值的字典，没有别名的组不包含在内。default含义同上。
>  4.start([group]):
>  返回指定的组截获的子串在string中的起始索引（子串第一个字符的索引）。group默认值为0。
>  5.end([group]):
>  返回指定的组截获的子串在string中的结束索引（子串最后一个字符的索引+1）。group默认值为0。
>  6.span([group]):
>  返回(start(group), end(group))。
>  7.expand(template):
>  将匹配到的分组代入template中然后返回。template中可以使用\id或\g、\g引用分组，但不能使用编号0。\id与\g是等价的；但\10将被认为是第10个分组，如果你想表达\1之后是字符’0’，只能使用\g0。

## re模块

> ❀re.match(pattern, string[, flags]):从头匹配string，失败（不匹配，匹配未完成）返回none，成功则终止
>
> 例如：
>
> ```python
> import re
> pattern=re.compile(r'hahao')
> result=re.match(pattern,'hahahaha')#😭
> result=re.match(pattern,'hahaoha')#😀
> result=re.match(pattern,'haha o')#😭
> result=re.match(pattern,'hahao')#😀
> ```
>
> ❀re.search(pattern, string[, flags])：非从头开始匹配，其他和re.match一样
>
> 例如：
>
> ```
> import re
> pattern=re.compile(r'hahao')
> result=re.search(pattern,'kkhahaa')#😭
> result=re.rearch(pattern,'Kkhahaoha')#😀
> result=re.rearch(pattern,'haha o')#😭
> result=re.search(pattern,'hahao')#😀
> ```
>
> 